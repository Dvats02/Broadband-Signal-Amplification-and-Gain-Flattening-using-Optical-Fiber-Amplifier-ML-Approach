# ðŸ“¶ Broadband Signal Amplification using Machine Learning

This project uses machine learning techniques to optimize broadband signal amplification, targeting efficient prediction and configuration of pump parameters for achieving desired signal gains. It leverages neural networks to model complex relationships between signal and pump parameters.

## ðŸ§  Problem Statement

Design and train a machine learning model to predict:
- Optimal **Pumping Wavelength (nm)**
- Required **Pump Power (mW)**

Based on:
- **Signal Wavelength (nm)**
- Desired **Signal Gain (dB)**

## ðŸ”§ Technologies Used

- Python
- TensorFlow / Keras
- NumPy, Pandas, Scikit-learn
- Matplotlib, Seaborn


## ðŸ“Š Model Performance

- âœ… **Best Accuracy (RÂ² Score):** ~0.89
- âœ… **Loss Metric Used:** Mean Absolute Error (MAE), Mean Squared Error (MSE)
- âœ… **Optimization Techniques:** Grid Search, Cross Validation

## ðŸ“Œ Key Features

- Realistic simulation of signal gain behavior
- Prediction of pump parameters to match desired amplification
- Suitable for optical communication system design
- 
ðŸš€ How to Run
# Open Final_Model.ipynb and run all cells
